{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0337fdea-9b87-407b-916d-36195d1fde1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/openai/whisper.git@248b6cb124225dd263bb9bd32d060b6517e067f8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cb425e3-c76e-47d8-afbb-fff95a645710",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8fa23b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#important\n",
    "#!pip install librosa==0.9.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33798437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scipy\n",
    "#!pip install datasets>=2.6.1\n",
    "#!pip install git+https://github.com/huggingface/transformers\n",
    "#!pip install librosa\n",
    "#!pip install evaluate>=0.30\n",
    "#!pip install jiwer\n",
    "#!pip install gradio\n",
    "#!pip install transformers[torch]\n",
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8eb4fd1-f54e-47f6-93cc-abc17e45509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch \n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "450df9f9-e16f-4b55-b60e-35d800018219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Load the list from the file\n",
    "with open(\"/home/projects/dharel/eranbe/Eran/all_data_list_poc_segprotfoc_include21.pkl\", 'rb') as f:\n",
    "    tal_alona_pkl_best_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eea71c3a-3b7a-4e60-801e-95f830ed9dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order matter!\n",
    "\n",
    "all_data_list = tal_alona_pkl_best_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05d4a114-60b1-4074-ae58-cd358dba7d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2e6aa52-e831-47e2-8b27-0b2cc568f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0512ce3e-7ad8-496d-9ce7-66b7821ebedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    row['audio']['array'] = np.array(row['audio']['array'], dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6caff6f6-3dfa-436b-8f2d-0a1abb2e1c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "\n",
    "seed = 123  # you can choose any integer seed you like\n",
    "\n",
    "train_df = df.iloc[:int(0.95*len(df))] # very important line of code, in order for not mix test with train\n",
    "train_df = train_df.sample(frac=1, random_state=seed).reset_index(drop=True)  # deterministic shuffle and reset index\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "\n",
    "\n",
    "# Create the Dataset objects\n",
    "#train_dataset = Dataset.from_pandas(df.iloc[:int(0.95*len(df))])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_dataset = Dataset.from_pandas(df.iloc[int(0.95*len(df)):])\n",
    "\n",
    "# Create the DatasetDict object\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1091f019-3871-4c6f-80b6-dc5d7f785712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'sentence'],\n",
       "        num_rows: 1168\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['audio', 'sentence'],\n",
       "        num_rows: 62\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58caaa9f-fdb5-49a1-a792-983f7f27ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/projects/dharel/eranbe/Eran/whisper_seg_focus_prototype_wexac_22_07_2023_v2booya_offline/checkpoint-4000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d3dca40-0135-4606-8554-2110975e8a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperFeatureExtractor\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "796ede8c-99ea-47b4-9177-99909dc37fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperTokenizer\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(path, language=\"english\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d2b64c9-4505-4d0e-8510-71a7bf008302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(path, language=\"english\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40acc5b6-b2d3-4c33-9198-715847582a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to trancate sequence ,model works only with 1024 token.\n",
    "#@@@@@@@@@@\n",
    "#@@@@@@@@@@\n",
    "#$$$$$$$$$$$$$$$$$\n",
    "#MAX_LENGTH = 1024\n",
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array \n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "    # truncate target text to a maximum length\n",
    "    #sentence = batch[\"sentence\"][:MAX_LENGTH]\n",
    "    sentence = batch[\"sentence\"]\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # split the string into list of words\n",
    "    words = sentence.split()\n",
    "\n",
    "    # define the markers\n",
    "    markers = ['TRUE1TRUE', 'FALSE1TRUE', 'TRUE2TRUE', 'FALSE2TRUE', 'TRUE3TRUE', 'FALSE3TRUE', 'TRUE1FALSE', 'FALSE1FALSE', 'TRUE2FALSE', 'FALSE2FALSE', 'TRUE3FALSE', 'FALSE3FALSE']\n",
    "\n",
    "    # process the words\n",
    "    output_words = [word.lower() if word not in markers else word for word in words]\n",
    "\n",
    "    # join the words back into a string\n",
    "    sentence = ' '.join(output_words)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # compute input length of audio sample in seconds\n",
    "    batch[\"input_length\"] = len(audio[\"array\"]) / audio[\"sampling_rate\"]\n",
    "    # encode target text to label ids \n",
    "    labels_ids = tokenizer(sentence).input_ids\n",
    "    # truncate labels to a maximum length\n",
    "    #labels_ids = labels_ids[:MAX_LENGTH]\n",
    "    batch[\"labels\"] = labels_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27018b1d-13fa-4313-ac11-68c8d2950f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/1168 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (6891 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2643 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3800 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1704 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4523 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/62 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset_dict.map(prepare_dataset, remove_columns=dataset_dict.column_names[\"train\"], num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e11da21c-7cb8-4cd0-8f27-1f82871fecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 30\n",
    "min_input_length = 0\n",
    "\n",
    "\n",
    "def is_audio_in_length_range(length):\n",
    "    return length > min_input_length and length <= max_input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98bde5dd-500a-451f-be73-3dcb571415b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1168 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/62 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_features', 'input_length', 'labels'],\n",
       "        num_rows: 1134\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_features', 'input_length', 'labels'],\n",
       "        num_rows: 61\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_datasets = dataset.filter(\n",
    "    is_audio_in_length_range, num_proc=1, input_columns=[\"input_length\"]\n",
    ")\n",
    "\n",
    "vectorized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "947d7eaa-e0bd-427a-a9b5-991c80fbc8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "120461f3-c184-49fc-9812-95fb10ca71f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "745fe2d5-53ba-4676-9986-52460fd78d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"english\", task=\"transcribe\")\n",
    "\n",
    "model.config.suppress_tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2c688a1-55bd-4cf2-b824-004e3d15bb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_label_length = model.config.max_length\n",
    "max_label_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95005f63-17dc-4d5c-98fc-05f328ec5714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_labels_in_length_range(labels):\n",
    "    return len(labels) < max_label_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed2b4a83-66bd-4929-84a1-6302fc96f29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1134 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/61 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_features', 'input_length', 'labels'],\n",
       "        num_rows: 1131\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_features', 'input_length', 'labels'],\n",
       "        num_rows: 61\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_datasets = vectorized_datasets.filter(\n",
    "    is_labels_in_length_range, num_proc=1, input_columns=[\"labels\"]\n",
    ")\n",
    "\n",
    "vectorized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bc4942d-c1eb-40aa-9e8d-67b2a34849fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice = vectorized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbacc888-bf7b-4a9c-9fd8-8fdd6793a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "        print(batch)\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "        print(labels)\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9c4196f-e6d3-44e4-b93c-693a7d8d7b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ed3bfca-ea02-47df-96de-cb5e42a5d108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7da45e75-be9e-4d2d-aa89-78af3c5cfe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34972ff5-a883-4591-a281-47ee6f7b300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "#pipe = pipeline('automatic-speech-recognition',\"/content/drive/MyDrive/Weizmann/whisper_focus_segmentation/FOCUS_SEGMENTATION_WITH_DATAISSUE/checkpoint-3000\",chunk_length_s=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bca3ecbc-5743-4f01-87d3-9eb848cc7168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eecd1c39-df54-4e99-8d97-a83d947a3633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def transcribe(audio):\n",
    "    y, sr = librosa.load(audio)\n",
    "    audio = librosa.resample(y, sr, 16000)\n",
    "    #text = pipe(audio.flatten())[\"text\"]\n",
    "    #return transform_2_df(text)#bold_words(transform_to_prototype(transform_2_df(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e8738ce-390f-4385-b120-adffe3b1c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d1152bf-91b3-4488-92e7-3368703fade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "304a513f-b112-431a-85fb-dab0d645a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_key_change = pd.read_csv(f\"/home/projects/dharel/eranbe/Eran/model_parameters_key_change_from_hf_to_wisper.csv\")\n",
    "hf_key_change = hf_key_change.assign(hagginface_w_prefix = \"model.\" + hf_key_change.hagginface)\n",
    "hf_key_change_dict = hf_key_change.set_index(\"hagginface_w_prefix\")[\"whisper\"].to_dict()\n",
    "#hf_key_change_dict = hf_key_change.set_index(\"hagginface\")[\"whisper\"].to_dict()\n",
    "state_dict = torch.load(path+\"/pytorch_model.bin\",map_location=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "055a96d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_dict_correct = OrderedDict([(hf_key_change_dict[k],v) for k,v in state_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2eab7f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_dict_correct = OrderedDict([(hf_key_change_dict[k],v) for k,v in state_dict.items()])\n",
    "state_dict_correct = OrderedDict([(hf_key_change_dict[k],v) for k,v in state_dict.items() if k != 'proj_out.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d52b549a-0e4c-4497-b660-8858ca2eb71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"large-v2\",download_root=\"/home/projects/dharel/eranbe/Eran/whisper-large-base\",device=device)\n",
    "#model = whisper.load_model(\"large\",download_root=\"/whisper-large-base\",device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5e4c36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2b58de2-bd89-4f10-9753-07333dfb2171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Whisper(\n",
       "  (encoder): AudioEncoder(\n",
       "    (conv1): Conv1d(80, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (blocks): ModuleList(\n",
       "      (0-31): 32 x ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): TextDecoder(\n",
       "    (token_embedding): Embedding(51865, 1280)\n",
       "    (blocks): ModuleList(\n",
       "      (0-31): 32 x ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e34575e5-17d4-499b-815a-5980dcfbc3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_whisper_tagging(transcription, audio_path, model):\n",
    "    \"\"\"\n",
    "    This methods applied the next tactic for getting prediction for each word in the transcript:\n",
    "     - t <- initial tokens\n",
    "     - for each word in the transcript:\n",
    "      - predict the next token for the last token in t\n",
    "      - repeat previous step three times to get TRUE/FALSE + 1/2/3 + TRUE/FALSE\n",
    "      - add the word tokens to t\n",
    "      - update dataframe with the added word and the generated tags\n",
    "    @param transcription: lower case words seperated by spaces\n",
    "    @param audio_features: features generated from the audio matching the transcript\n",
    "    @param model: the whisper model\n",
    "    @return: df with prediction for each word in the transcript, string output of the model\n",
    "    \"\"\"\n",
    "\n",
    "    mel = whisper.audio.log_mel_spectrogram(audio_path)\n",
    "    mel = whisper.audio.pad_or_trim(mel, length=whisper.audio.N_FRAMES)\n",
    "    with torch.no_grad():\n",
    "        audio_features = model.encoder(mel.unsqueeze(0).to(model.device))\n",
    "\n",
    "    # getting tokenizer\n",
    "    tokenizer = whisper.tokenizer.get_tokenizer(True)\n",
    "    device = model.device\n",
    "\n",
    "    transcription_parts_wo_spaces = [p for p in transcription.split(\" \")] \n",
    "    transcription_parts = [\" \" + p for p in transcription_parts_wo_spaces] # \" w1\" + \" w2\" + \" w3\"\n",
    "    transcription_parts_tokens = [tokenizer.encode(p) for p in transcription_parts]\n",
    "\n",
    "    starting_tokens = [50258, 50259, 50359, 50364]  # '<|startoftranscript|><|en|><|transcribe|>'. last token is ''\n",
    "\n",
    "    res_segmentation = []\n",
    "    res_prototype = []\n",
    "    res_emphasis = []\n",
    "\n",
    "    tokens = starting_tokens\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(transcription_parts_tokens)):\n",
    "            ### Segmentation running the model to figure out segmentation\n",
    "            tokens_tensor = torch.Tensor([tokens]).int().to(device)\n",
    "            \n",
    "            logits_for_transcript = model.decoder(tokens_tensor, audio_features)\n",
    "            logits_for_transcript = logits_for_transcript.detach().cpu()\n",
    "            logits_for_transcript = logits_for_transcript[:, -1]\n",
    "            # filters - everything is -inf other than ' TR',' F','TR','F'\n",
    "            tokens_to_choose_from = tokenizer.encode(\" TR FTRF\") \n",
    "            tokens_to_choose = logits_for_transcript[:, tokens_to_choose_from]\n",
    "            logits_for_transcript[:, :] = -np.inf\n",
    "            logits_for_transcript[:, tokens_to_choose_from] = tokens_to_choose\n",
    "\n",
    "            best_tokens = logits_for_transcript.argmax(-1, True)\n",
    "\n",
    "            best_tokens_int = best_tokens.cpu().detach().numpy()[0][0]\n",
    "\n",
    "            tokens = tokens + [best_tokens_int]\n",
    "            if tokens[-1] in tokenizer.encode(\" TRTR\"):\n",
    "                tokens = tokens + tokenizer.encode(\"UE\")\n",
    "                res_segmentation.append(True)\n",
    "            else:\n",
    "                tokens = tokens + tokenizer.encode('ALSE')\n",
    "                res_segmentation.append(False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            ### Prototype running the model to figure out prototype\n",
    "            tokens_tensor = torch.Tensor([tokens]).int().to(device)\n",
    "            \n",
    "            logits_for_transcript = model.decoder(tokens_tensor, audio_features)\n",
    "            logits_for_transcript = logits_for_transcript.detach().cpu()\n",
    "            logits_for_transcript = logits_for_transcript[:, -1]\n",
    "            # filters - everything is -inf other than '1','2'\n",
    "            tokens_to_choose_from = tokenizer.encode(\"1\") + tokenizer.encode(\"2\") + tokenizer.encode(\"3\")\n",
    "            tokens_to_choose = logits_for_transcript[:, tokens_to_choose_from]\n",
    "            logits_for_transcript[:, :] = -np.inf\n",
    "            logits_for_transcript[:, tokens_to_choose_from] = tokens_to_choose\n",
    "\n",
    "            best_tokens = logits_for_transcript.argmax(-1, True)\n",
    "            best_tokens_int = best_tokens.cpu().detach().numpy()[0][0]\n",
    "            res_prototype.append(tokenizer.decode((best_tokens_int,))[0])\n",
    "\n",
    "            tokens = tokens + [best_tokens_int]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            ### Focus running the model to figure out emphasis\n",
    "            tokens_tensor = torch.Tensor([tokens]).int().to(device)\n",
    "            \n",
    "            logits_for_transcript = model.decoder(tokens_tensor, audio_features)\n",
    "            logits_for_transcript = logits_for_transcript.detach().cpu()\n",
    "            logits_for_transcript = logits_for_transcript[:, -1]\n",
    "            # filters - everything is -inf other than ' TR',' F','TR','F'\n",
    "            tokens_to_choose_from = tokenizer.encode(\" TR FTRF\")\n",
    "            tokens_to_choose = logits_for_transcript[:, tokens_to_choose_from]\n",
    "            logits_for_transcript[:, :] = -np.inf\n",
    "            logits_for_transcript[:, tokens_to_choose_from] = tokens_to_choose\n",
    "\n",
    "            best_tokens = logits_for_transcript.argmax(-1, True)\n",
    "\n",
    "            best_tokens_int = best_tokens.cpu().detach().numpy()[0][0]\n",
    "\n",
    "            tokens = tokens + [best_tokens_int]\n",
    "            if tokens[-1] in tokenizer.encode(\" TRTR\"):\n",
    "                tokens = tokens + tokenizer.encode(\"UE\")\n",
    "                res_emphasis.append(True)\n",
    "            else:\n",
    "                tokens = tokens + tokenizer.encode('ALSE')\n",
    "                res_emphasis.append(False)\n",
    "\n",
    "            ### Adding next word token\n",
    "            tokens = tokens + transcription_parts_tokens[i]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    expected_regular_model_result = tokenizer.decode(\n",
    "        tokens[len(starting_tokens):]\n",
    "    )\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        \"word\": transcription_parts_wo_spaces,\n",
    "        \"segmentation\": res_segmentation ,\n",
    "        \"prototype\": res_prototype,\n",
    "        \"emphasis\": res_emphasis, \n",
    "    })\n",
    "    return result_df, expected_regular_model_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20226963-a44e-4929-b95f-2395da38a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_mem():\n",
    "    \"\"\"\n",
    "    returns the amount of free memory in cuda in GB\n",
    "    \"\"\"\n",
    "    # t = torch.cuda.get_device_properties(0).total_memory\n",
    "    r = torch.cuda.memory_reserved(0)\n",
    "    a = torch.cuda.memory_allocated(0)\n",
    "    f = r - a  # free inside reserved\n",
    "    return f / 1024 ** 3\n",
    "\n",
    "\n",
    "def get_audio_features_from_mel(mel, model):\n",
    "    mel = whisper.audio.pad_or_trim(mel,length=whisper.audio.N_FRAMES)\n",
    "    with torch.no_grad():\n",
    "        audio_features = model.encoder(mel.unsqueeze(0).to(model.device))\n",
    "    # n_group = 1  # beam search parameter (how many candidates to keep track of?)\n",
    "    # audio_features = audio_features.repeat_interleave(n_group, dim=0)\n",
    "    return audio_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a762eb0-3b9b-4bb0-a271-abc1a7c35609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def transform_2_df(orig_df):\n",
    "    new_df_list = []\n",
    "\n",
    "    for _, row in orig_df.iterrows():\n",
    "        sentence = row['sentence']\n",
    "        audio_array = row['audio_array']\n",
    "\n",
    "        words = []\n",
    "        flags = []\n",
    "\n",
    "        for token in sentence.split():\n",
    "            if token.startswith(\"TRUE\") or token.startswith(\"FALSE\"):\n",
    "                flags.append(token)\n",
    "            else:\n",
    "                words.append(token)\n",
    "\n",
    "        min_length = min(len(words), len(flags))\n",
    "\n",
    "        data = {\"FOCUS_SEGMENTATION_PROTOTYPE\": flags[:min_length]}\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # add the words column\n",
    "        df['WORDS'] = words[:min_length]\n",
    "\n",
    "        # add the audio array column\n",
    "        df['ARRAY'] = [audio_array] * min_length\n",
    "\n",
    "        # add the index column\n",
    "        df['INDEX'] = [row.name] * min_length\n",
    "\n",
    "        # append the DataFrame to the list\n",
    "        new_df_list.append(df[['FOCUS_SEGMENTATION_PROTOTYPE', 'WORDS', 'ARRAY', 'INDEX']])\n",
    "\n",
    "    # concatenate all the DataFrames in the list into a single DataFrame\n",
    "    new_df = pd.concat(new_df_list, ignore_index=True)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "# Updated function\n",
    "\n",
    "\n",
    "def transform_2_df2(input_str):\n",
    "    words = []\n",
    "    flags = []\n",
    "\n",
    "    for token in input_str.split():\n",
    "        if token.startswith(\"TRUE\") or token.startswith(\"FALSE\"):\n",
    "            flags.append(token)\n",
    "        else:\n",
    "            words.append(token)\n",
    "\n",
    "    min_length = min(len(words), len(flags))\n",
    "\n",
    "    data = {\"col2\": flags[:min_length]}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # split the second column\n",
    "    df[['SEGMENTATION', 'PROTOTYPE','FOCUS']] = df['col2'].str.extract('(TRUE|FALSE)(\\d)(TRUE|FALSE)', expand=True)\n",
    "    \n",
    "    # add the words column\n",
    "    df['WORDS'] = words[:min_length]\n",
    "\n",
    "    return df[['SEGMENTATION','PROTOTYPE','FOCUS', 'WORDS']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2d5aa18e-76a1-4247-bfcb-f0b7c8d7a182",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_DF = df.iloc[int(0.95*len(df)):] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2049e206-a372-4db5-894f-d1266f0c5ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame and 'audio' is your column.\n",
    "VALIDATION_DF['audio_array'] = VALIDATION_DF['audio'].apply(lambda x: x['array'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b31b90ac-d052-41f3-a5c6-b1431ad0db90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>sentence</th>\n",
       "      <th>audio_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>{'path': '/home/eranbe/dharelg/datasets/whispe...</td>\n",
       "      <td>TRUE3FALSE And FALSE3FALSE the FALSE3TRUE medi...</td>\n",
       "      <td>[0.00070413994, 0.00093696994, 0.00059676066, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>{'path': '/home/eranbe/dharelg/datasets/whispe...</td>\n",
       "      <td>TRUE2TRUE Yeah TRUE3FALSE The FALSE3TRUE attac...</td>\n",
       "      <td>[-0.0011175656, -0.0015582022, -0.0015195274, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>{'path': '/home/eranbe/dharelg/datasets/whispe...</td>\n",
       "      <td>TRUE2FALSE long FALSE2TRUE time TRUE3FALSE And...</td>\n",
       "      <td>[0.036355555, 0.04650424, 0.023045568, 0.01195...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>{'path': '/home/eranbe/dharelg/datasets/whispe...</td>\n",
       "      <td>TRUE2TRUE I FALSE2FALSE don't FALSE2FALSE have...</td>\n",
       "      <td>[-0.09080503, -0.14662455, -0.14236635, -0.168...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>{'path': '/home/eranbe/dharelg/datasets/whispe...</td>\n",
       "      <td>TRUE3TRUE Frank TRUE1TRUE once FALSE1FALSE thi...</td>\n",
       "      <td>[-0.0006250964, -0.0011925529, -0.0017315487, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  audio  \\\n",
       "1168  {'path': '/home/eranbe/dharelg/datasets/whispe...   \n",
       "1169  {'path': '/home/eranbe/dharelg/datasets/whispe...   \n",
       "1170  {'path': '/home/eranbe/dharelg/datasets/whispe...   \n",
       "1171  {'path': '/home/eranbe/dharelg/datasets/whispe...   \n",
       "1172  {'path': '/home/eranbe/dharelg/datasets/whispe...   \n",
       "\n",
       "                                               sentence  \\\n",
       "1168  TRUE3FALSE And FALSE3FALSE the FALSE3TRUE medi...   \n",
       "1169  TRUE2TRUE Yeah TRUE3FALSE The FALSE3TRUE attac...   \n",
       "1170  TRUE2FALSE long FALSE2TRUE time TRUE3FALSE And...   \n",
       "1171  TRUE2TRUE I FALSE2FALSE don't FALSE2FALSE have...   \n",
       "1172  TRUE3TRUE Frank TRUE1TRUE once FALSE1FALSE thi...   \n",
       "\n",
       "                                            audio_array  \n",
       "1168  [0.00070413994, 0.00093696994, 0.00059676066, ...  \n",
       "1169  [-0.0011175656, -0.0015582022, -0.0015195274, ...  \n",
       "1170  [0.036355555, 0.04650424, 0.023045568, 0.01195...  \n",
       "1171  [-0.09080503, -0.14662455, -0.14236635, -0.168...  \n",
       "1172  [-0.0006250964, -0.0011925529, -0.0017315487, ...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VALIDATION_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e83594d4-0251-44df-a00d-063ac252cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0120f1d6-0200-4d41-b65b-87de9fa8e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example_df_pred(INDEX,VALIDATION = VALIDATION_DF):\n",
    "  # Assuming df is your DataFrame and 'audio' is your column.\n",
    "  VALIDATION_DF['audio_array'] = VALIDATION_DF['audio'].apply(lambda x: x['array'])\n",
    "  df2 = transform_2_df(VALIDATION_DF)\n",
    "  transcript1178 = \" \".join(df2[df2.INDEX==INDEX].WORDS)\n",
    "  path_np1178 = df2[df2.INDEX==INDEX].ARRAY.iloc[0]\n",
    "  res_df, res_str = get_whisper_tagging(transcript1178,path_np1178,model)\n",
    "  df_true = transform_2_df2(VALIDATION_DF.loc[INDEX].sentence)\n",
    "  df_pred = res_df\n",
    "  merge_result = pd.merge(df_true,df_pred,left_index = True, right_index = True)\n",
    "  merge_result_rename = merge_result.rename(columns={\n",
    "      'FOCUS': 'focus_true',\n",
    "      'SEGMENTATION': 'segmentation_true',\n",
    "      'word': 'word_pred',\n",
    "      'WORDS': 'word_true',\n",
    "      'segmentation': 'segmentation_pred',\n",
    "      'emphasis': 'focus_pred',\n",
    "      'PROTOTYPE': 'prototype_true',\n",
    "      'prototype': 'prototype_pred'\n",
    "  })\n",
    "\n",
    "  merge_result_rename_reordered = merge_result_rename[['focus_true','focus_pred','segmentation_true','segmentation_pred','prototype_true','prototype_pred','word_true','word_pred']]\n",
    "  return merge_result_rename_reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "73813ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=1168, stop=1230, step=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VALIDATION_DF.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bb2c440a-933a-4ddd-a143-81038d2c6968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nturns_number_list = [1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130,\\n       1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141,\\n       1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152,\\n       1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,\\n       1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174,\\n       1175, 1176, 1177, 1178]\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "turns_number_list = [1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130,\n",
    "       1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141,\n",
    "       1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152,\n",
    "       1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,\n",
    "       1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174,\n",
    "       1175, 1176, 1177, 1178]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f62aaa38-ee60-45c4-9c43-eb4ddb51d551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(turns_number_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d960caa6-6096-4b78-9f8e-463b274d14c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "pred_dfs = []\n",
    "for num in VALIDATION_DF.index:\n",
    "  pred_dfs.append(create_example_df_pred(num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01b1c412-95e9-4bb2-8367-1bd0bb3a9e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.concat(pred_dfs,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "49c46d0e-9bdc-491d-a38d-4631ccfb1a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to boolean\n",
    "pred_df['focus_true'] = pred_df['focus_true'].map({'TRUE': True, 'FALSE': False})\n",
    "# Convert to boolean\n",
    "pred_df['segmentation_true'] = pred_df['segmentation_true'].map({'TRUE': True, 'FALSE': False})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7fc1aa3a-370b-43ea-aea9-2f0f86734496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[658 108]\n",
      " [ 88 152]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(pred_df['focus_true'], pred_df['focus_pred'])\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3e54b6f5-3fb0-4b98-adc2-578270315131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "308deb95-b493-428f-931d-2c71ef963372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47864621893178205"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.cohen_kappa_score(pred_df['focus_true'], pred_df['focus_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "18e0895d-26b3-45d7-b7eb-d6a217051615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.934343132189378"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.cohen_kappa_score(pred_df['segmentation_true'], pred_df['segmentation_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7b5e8a8c-0aa5-4e9d-84ac-d9d500796933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6484800970581035"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.cohen_kappa_score(pred_df['prototype_true'], pred_df['prototype_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "20095e04-a7d6-4b06-8c2f-cc2ef5039911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems like 3000 itereations improve results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a9ef4ebe-9b22-45cd-94a9-4fcb30fa960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f95f5ab0-7b49-447d-8e3e-6b6143996916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9761431411530815"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred_df['segmentation_true'], pred_df['segmentation_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "55390730-7df3-4a2f-a493-ead387cbf5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.805168986083499"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred_df['focus_true'], pred_df['focus_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f66d968-9523-461c-a9e5-a74a05eb3566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca412aec",
   "metadata": {},
   "source": [
    "# metric for evaluating Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aa7f639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pypi.org/project/nervaluate/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "662ba030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nervaluate in /home/projects/dharel/eranbe/.local/lib/python3.8/site-packages (0.1.8)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nervaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3e6e21fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nervaluate\n",
    "from nervaluate import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0847740c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ent_type': {'correct': 3, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 0, 'possible': 3, 'actual': 3, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'partial': {'correct': 3, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 0, 'possible': 3, 'actual': 3, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'strict': {'correct': 3, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 0, 'possible': 3, 'actual': 3, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}, 'exact': {'correct': 3, 'incorrect': 0, 'partial': 0, 'missed': 0, 'spurious': 0, 'possible': 3, 'actual': 3, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "#example\n",
    "\n",
    "\n",
    "true = [\n",
    "    [{\"label\": \"PER\", \"start\": 2, \"end\": 4}],\n",
    "    [{\"label\": \"LOC\", \"start\": 1, \"end\": 2},\n",
    "     {\"label\": \"LOC\", \"start\": 3, \"end\": 4}]\n",
    "]\n",
    "\n",
    "pred = [\n",
    "    [{\"label\": \"PER\", \"start\": 2, \"end\": 4}],\n",
    "    [{\"label\": \"LOC\", \"start\": 1, \"end\": 2},\n",
    "     {\"label\": \"LOC\", \"start\": 3, \"end\": 4}]\n",
    "]\n",
    "\n",
    "from nervaluate import Evaluator\n",
    "\n",
    "evaluator = Evaluator(true, pred, tags=['LOC', 'PER'])\n",
    "\n",
    "# Returns overall metrics and metrics for each tag\n",
    "\n",
    "results, results_per_tag = evaluator.evaluate()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "be9b171d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'ent_type': {'correct': 2,\n",
       "   'incorrect': 0,\n",
       "   'partial': 0,\n",
       "   'missed': 0,\n",
       "   'spurious': 0,\n",
       "   'possible': 2,\n",
       "   'actual': 2,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'f1': 1.0},\n",
       "  'partial': {'correct': 2,\n",
       "   'incorrect': 0,\n",
       "   'partial': 0,\n",
       "   'missed': 0,\n",
       "   'spurious': 0,\n",
       "   'possible': 2,\n",
       "   'actual': 2,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'f1': 1.0},\n",
       "  'strict': {'correct': 2,\n",
       "   'incorrect': 0,\n",
       "   'partial': 0,\n",
       "   'missed': 0,\n",
       "   'spurious': 0,\n",
       "   'possible': 2,\n",
       "   'actual': 2,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'f1': 1.0},\n",
       "  'exact': {'correct': 2,\n",
       "   'incorrect': 0,\n",
       "   'partial': 0,\n",
       "   'missed': 0,\n",
       "   'spurious': 0,\n",
       "   'possible': 2,\n",
       "   'actual': 2,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'f1': 1.0}},\n",
       " 'PER': {'ent_type': {'correct': 1,\n",
       "   'incorrect': 0,\n",
       "   'partial': 0,\n",
       "   'missed': 0,\n",
       "   'spurious': 0,\n",
       "   'possible': 1,\n",
       "   'actual': 1,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'f1': 1.0},\n",
       "  'partial': {'correct': 1,\n",
       "   'incorrect': 0,\n",
       "   'partial': 0,\n",
       "   'missed': 0,\n",
       "   'spurious': 0,\n",
       "   'possible': 1,\n",
       "   'actual': 1,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'f1': 1.0},\n",
       "  'strict': {'correct': 1,\n",
       "   'incorrect': 0,\n",
       "   'partial': 0,\n",
       "   'missed': 0,\n",
       "   'spurious': 0,\n",
       "   'possible': 1,\n",
       "   'actual': 1,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'f1': 1.0},\n",
       "  'exact': {'correct': 1,\n",
       "   'incorrect': 0,\n",
       "   'partial': 0,\n",
       "   'missed': 0,\n",
       "   'spurious': 0,\n",
       "   'possible': 1,\n",
       "   'actual': 1,\n",
       "   'precision': 1.0,\n",
       "   'recall': 1.0,\n",
       "   'f1': 1.0}}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_per_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7d88c168-ea16-41c0-81bd-95532ec49cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def consecutive_numbers(lst: List[int]) -> List[Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    This function takes a list of numbers and returns a list of dictionaries.\n",
    "    Each dictionary represents a sequence of the same number in the input list.\n",
    "    The dictionary contains the number (flag), the start index, and the end index of the sequence.\n",
    "\n",
    "    :param lst: List of integers\n",
    "    :return: List of dictionaries representing sequences of the same number\n",
    "    \"\"\"\n",
    "    # Initialize empty result list\n",
    "    result = []\n",
    "\n",
    "    # Initialize start_index and current_flag to None\n",
    "    start_index = None\n",
    "    current_flag = None\n",
    "\n",
    "    # Iterate over the list with index\n",
    "    for i, item in enumerate(lst):\n",
    "        if start_index is None:  # Check if start_index is None, this indicates the start of a sequence\n",
    "            start_index = i\n",
    "            current_flag = item\n",
    "        elif item != current_flag:  # Check if the item is not equal to current_flag, this indicates the end of a sequence\n",
    "            # Add the sequence (start_index to i-1) to the result list\n",
    "            result.append({\n",
    "                \"label\": str(current_flag),\n",
    "                \"start\": start_index,\n",
    "                \"end\": i - 1\n",
    "            })\n",
    "            start_index = i  # Set the current index as the start_index for the next sequence\n",
    "            current_flag = item  # Set the current item as the flag for the next sequence\n",
    "\n",
    "    # After the loop, check if there is an unfinished sequence. If yes, add it to the result.\n",
    "    if start_index is not None:\n",
    "        result.append({\n",
    "            \"label\": str(current_flag),\n",
    "            \"start\": start_index,\n",
    "            \"end\": len(lst) - 1  # The end index of the last sequence is the last index of the list\n",
    "        })\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "09891f9f-ec69-4c65-9c36-3df10cdb783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [1, 1, 1, 2, 2, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "27bc3f02-b25a-4a23-aba9-2b8091cc6610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': '1', 'start': 0, 'end': 2}, {'label': '2', 'start': 3, 'end': 6}]\n"
     ]
    }
   ],
   "source": [
    "print(consecutive_numbers(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d8c26aa4-1012-4326-9e7f-38c8498326e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "true =  [consecutive_numbers(list(pred_df['prototype_true']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "533adf50-2ba3-4cd6-85af-52b23489e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [consecutive_numbers(list(pred_df['prototype_pred']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "609f0845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '3', 'start': 0, 'end': 4},\n",
       " {'label': '2', 'start': 5, 'end': 11},\n",
       " {'label': '3', 'start': 12, 'end': 20},\n",
       " {'label': '2', 'start': 21, 'end': 22},\n",
       " {'label': '3', 'start': 23, 'end': 26}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "668ec28d-02b2-4b3e-896c-0735e73452e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(true, pred, tags=['1', '2', '3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfb305b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aee27b5a-fd59-4c1d-aeea-71672c6c1dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nervaluate.nervaluate.Evaluator at 0x2ae8dcf9aa00>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "493cc749-838c-45ea-97b4-870080037a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    " results , results_per_tag = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f92ad952-2b7b-4198-a684-6a86cc5a5716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct': 7,\n",
       " 'incorrect': 2,\n",
       " 'partial': 0,\n",
       " 'missed': 1,\n",
       " 'spurious': 0,\n",
       " 'possible': 10,\n",
       " 'actual': 9,\n",
       " 'precision': 0.7777777777777778,\n",
       " 'recall': 0.7,\n",
       " 'f1': 0.7368421052631577}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_per_tag['1']['ent_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ed95b7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct': 35,\n",
       " 'incorrect': 6,\n",
       " 'partial': 0,\n",
       " 'missed': 10,\n",
       " 'spurious': 10,\n",
       " 'possible': 51,\n",
       " 'actual': 51,\n",
       " 'precision': 0.6862745098039216,\n",
       " 'recall': 0.6862745098039216,\n",
       " 'f1': 0.6862745098039216}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_per_tag['2']['ent_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1cf425f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct': 42,\n",
       " 'incorrect': 4,\n",
       " 'partial': 0,\n",
       " 'missed': 8,\n",
       " 'spurious': 6,\n",
       " 'possible': 54,\n",
       " 'actual': 52,\n",
       " 'precision': 0.8076923076923077,\n",
       " 'recall': 0.7777777777777778,\n",
       " 'f1': 0.7924528301886792}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_per_tag['3']['ent_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a103ceb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct': 84,\n",
       " 'incorrect': 12,\n",
       " 'partial': 0,\n",
       " 'missed': 19,\n",
       " 'spurious': 16,\n",
       " 'possible': 115,\n",
       " 'actual': 112,\n",
       " 'precision': 0.75,\n",
       " 'recall': 0.7304347826086957,\n",
       " 'f1': 0.7400881057268722}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['ent_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d0b8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bafe09ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '3', '3', '3', '3']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pred_df['prototype_true'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "48e6a170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ent_type': {'correct': 84,\n",
       "  'incorrect': 12,\n",
       "  'partial': 0,\n",
       "  'missed': 19,\n",
       "  'spurious': 16,\n",
       "  'possible': 115,\n",
       "  'actual': 112,\n",
       "  'precision': 0.75,\n",
       "  'recall': 0.7304347826086957,\n",
       "  'f1': 0.7400881057268722},\n",
       " 'partial': {'correct': 42,\n",
       "  'incorrect': 0,\n",
       "  'partial': 54,\n",
       "  'missed': 19,\n",
       "  'spurious': 16,\n",
       "  'possible': 115,\n",
       "  'actual': 112,\n",
       "  'precision': 0.6160714285714286,\n",
       "  'recall': 0.6,\n",
       "  'f1': 0.6079295154185023},\n",
       " 'strict': {'correct': 42,\n",
       "  'incorrect': 54,\n",
       "  'partial': 0,\n",
       "  'missed': 19,\n",
       "  'spurious': 16,\n",
       "  'possible': 115,\n",
       "  'actual': 112,\n",
       "  'precision': 0.375,\n",
       "  'recall': 0.3652173913043478,\n",
       "  'f1': 0.3700440528634361},\n",
       " 'exact': {'correct': 42,\n",
       "  'incorrect': 54,\n",
       "  'partial': 0,\n",
       "  'missed': 19,\n",
       "  'spurious': 16,\n",
       "  'possible': 115,\n",
       "  'actual': 112,\n",
       "  'precision': 0.375,\n",
       "  'recall': 0.3652173913043478,\n",
       "  'f1': 0.3700440528634361}}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bf0c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
